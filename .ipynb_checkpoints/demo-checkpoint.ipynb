{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import sys\n",
    "# from Trainers.DatasetBC import datasets\n",
    "from ExperimentsBC import train_dataset_on_encoders\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run experiments on a dataset')\n",
    "parser.add_argument('--dataset', type=str, default=\"imdb\")\n",
    "parser.add_argument(\"--data_dir\", type=str, default=\".\")\n",
    "parser.add_argument(\"--output_dir\", type=str,default=\"test_outputs/\")\n",
    "parser.add_argument('--encoder', type=str, choices=['lstm', 'average'], default=\"lstm\")\n",
    "parser.add_argument('--attention', type=str, choices=['tanh', 'frozen', 'pre-loaded'], default=\"tanh\")\n",
    "parser.add_argument('--n_iters', type=int, required=False, default=80)\n",
    "parser.add_argument('--seed', type=int, default=10)\n",
    "parser.add_argument('--gold_label_dir', type=str, required=False)\n",
    "parser.add_argument('--hidden_size', type=int, default=128)\n",
    "parser.add_argument('--lmbda', type=float, required=False)\n",
    "parser.add_argument('--adversarial', action='store_const', required=False, const=True)\n",
    "parser.add_argument('--ours', action='store_true')\n",
    "\n",
    "parser.add_argument('--pgd_radius', type=float,default=0.2)\n",
    "parser.add_argument('--pgd_step', type=float,default=10)\n",
    "parser.add_argument('--pgd_step_size', type=float,default=0.04)\n",
    "parser.add_argument('--pgd_norm_type', type=str,default=\"l-infty\")\n",
    "parser.add_argument('--lambda_1', type=float, default=1e-2)\n",
    "parser.add_argument('--lambda_2', type=float, default=1e-2)\n",
    "parser.add_argument('--exp_name', type=str, default=\"debug\")\n",
    "parser.add_argument('--K', type=int, default=4)\n",
    "parser.add_argument('--topk_prox_metric', type=str, choices=['l1', 'l2',\"kl-full\", 'jsd-full',\"kl-topk\", 'jsd-topk'], default='l1')\n",
    "\n",
    "parser.add_argument(\n",
    "        '-f',\n",
    "        '--file',\n",
    "        help='Path for input file. First line should contain number of lines to search in'\n",
    "    )\n",
    "\n",
    "args, extras = parser.parse_known_args()\n",
    "args.extras = extras\n",
    "args.command = ' '.join(['python'] + sys.argv)\n",
    "#\n",
    "# wandb.init(project=\"XAI-NLP\", entity=\"yixin\",config=args)\n",
    "# wandb.log(vars(args))\n",
    "\n",
    "# check that have provided a data directory to load attentions/predictions from\n",
    "if (args.attention == 'pre-loaded' or args.adversarial) and not args.gold_label_dir :\n",
    "    raise Exception(\"You must specify a gold-label directory for attention distributions\")\n",
    "\n",
    "#check that have provided the correct dir:\n",
    "if args.gold_label_dir and args.dataset.lower() not in args.gold_label_dir and args.dataset not in args.gold_label_dir :\n",
    "    raise Exception(\"Gold-attention labels directory does not match specified dataset\")\n",
    "\n",
    "# add check for lmbda value if adversarial model\n",
    "if args.adversarial and not args.lmbda :\n",
    "    raise Exception(\"Must specify a lambda value for the adversarial model\")\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# frozen_attn means uniform\n",
    "\n",
    "if args.adversarial or args.ours :\n",
    "    args.frozen_attn = False\n",
    "    args.pre_loaded_attn = False\n",
    "elif args.attention == 'frozen' :\n",
    "    args.frozen_attn = True\n",
    "    args.pre_loaded_attn = False\n",
    "elif args.attention == 'tanh' :\n",
    "    args.frozen_attn = False\n",
    "    args.pre_loaded_attn = False\n",
    "elif args.attention == 'pre-loaded': # not an adversarial model\n",
    "    args.frozen_attn = False\n",
    "    args.pre_loaded_attn = True\n",
    "else :\n",
    "    raise LookupError(\"Attention not found ...\")\n",
    "\n",
    "\n",
    "if args.adversarial or args.ours :\n",
    "    exp_name = '+'.join((args.encoder, 'adversarial'))\n",
    "else :\n",
    "    exp_name = '+'.join((args.encoder, args.attention))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# exp_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "from attention.preprocess import vectorizer\n",
    "\n",
    "def sortbylength(X, y) :\n",
    "    len_t = np.argsort([len(x) for x in X])\n",
    "    X1 = [X[i] for i in len_t]\n",
    "    y1 = [y[i] for i in len_t]\n",
    "    return X1, y1\n",
    "\n",
    "def filterbylength(X, y, min_length = None, max_length = None) :\n",
    "    lens = [len(x)-2 for x in X]\n",
    "    min_l = min(lens) if min_length is None else min_length\n",
    "    max_l = max(lens) if max_length is None else max_length\n",
    "\n",
    "    idx = [i for i in range(len(X)) if len(X[i]) > min_l+2 and len(X[i]) < max_l+2]\n",
    "    X = [X[i] for i in idx]\n",
    "    y = [y[i] for i in idx]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def set_balanced_pos_weight(dataset) :\n",
    "    y = np.array(dataset.train_data.y)\n",
    "    dataset.pos_weight = [len(y) / sum(y) - 1] # N/P\n",
    "\n",
    "class DataHolder() :\n",
    "    def __init__(self, X, y, y_attn=None, true_pred=None) :\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.gold_attns = y_attn\n",
    "        self.true_pred = true_pred\n",
    "        self.attributes = ['X', 'y', 'gold_attns', 'true_pred']\n",
    "\n",
    "\n",
    "class Dataset() :\n",
    "    def __init__(self, name, path, min_length=None, max_length=None, args=None) :\n",
    "        self.name = name\n",
    "        if args is not None and hasattr(args, 'data_dir') :\n",
    "            path = os.path.join(args.data_dir, path)\n",
    "\n",
    "        self.vec = pickle.load(open(path, 'rb'))\n",
    "\n",
    "        X, Xt = self.vec.seq_text['train'], self.vec.seq_text['test'] # these are lists (of lists) of num. insts-length (NOT PADDED)\n",
    "        y, yt = self.vec.label['train'], self.vec.label['test']\n",
    "\n",
    "        X, y = filterbylength(X, y, min_length=min_length, max_length=max_length)\n",
    "        Xt, yt = filterbylength(Xt, yt, min_length=min_length, max_length=max_length)\n",
    "        Xt, yt = sortbylength(Xt, yt)\n",
    "\n",
    "        if args.pre_loaded_attn or args.adversarial or args.ours :\n",
    "            # these are lists of lists, with some residual padding\n",
    "            y_attn = json.load(open(os.path.join(args.gold_label_dir, 'train_attentions_best_epoch.json'), 'r'))\n",
    "            yt_attn = json.load(open(os.path.join(args.gold_label_dir, 'test_attentions_best_epoch.json'), 'r'))\n",
    "\n",
    "            true_pred = json.load(open(os.path.join(args.gold_label_dir, 'train_predictions_best_epoch.json'), 'r'))\n",
    "            true_pred_t = json.load(open(os.path.join(args.gold_label_dir, 'test_predictions_best_epoch.json'), 'r'))\n",
    "            true_pred = [e[0] for e in true_pred]\n",
    "            true_pred_t = [e[0] for e in true_pred_t] #these are lists of num. insts-length\n",
    "\n",
    "            #trim padding from static attentions\n",
    "            new_attns = []\n",
    "            for e, a in zip(X, y_attn):\n",
    "                tmp = [0] + [el for el in a if el != 0] + [0]\n",
    "                assert len(tmp) == len(e)\n",
    "                new_attns.append(tmp)\n",
    "            y_attn = new_attns\n",
    "\n",
    "            #do the same for test\n",
    "            new_attns = []\n",
    "            for e, a in zip(Xt, yt_attn):\n",
    "                tmp = [0] + [el for el in a if el != 0] + [0]\n",
    "                assert len(tmp) == len(e)\n",
    "                new_attns.append(tmp)\n",
    "            yt_attn = new_attns\n",
    "\n",
    "            self.train_data = DataHolder(X, y, y_attn, true_pred)\n",
    "            self.test_data = DataHolder(Xt, yt, yt_attn, true_pred_t)\n",
    "\n",
    "        else :\n",
    "            self.train_data = DataHolder(X, y)\n",
    "            self.test_data = DataHolder(Xt, yt)\n",
    "\n",
    "        if args is not None and hasattr(args, 'hidden_size') :\n",
    "            self.hidden_size = args.hidden_size\n",
    "\n",
    "        self.output_size = 1\n",
    "        self.save_on_metric = 'roc_auc'\n",
    "        self.keys_to_use = {\n",
    "            'roc_auc' : 'roc_auc',\n",
    "            'pr_auc' : 'pr_auc'\n",
    "        }\n",
    "\n",
    "        self.bsize = 32\n",
    "        if args is not None and hasattr(args, 'output_dir') :\n",
    "            self.basepath = args.output_dir\n",
    "\n",
    "\n",
    "########################################## Dataset Loaders ################################################################################\n",
    "\n",
    "def SST_dataset(args=None) :\n",
    "    dataset = Dataset(name='sst', path='preprocess/SST/vec_sst.p', min_length=5, args=args)\n",
    "    set_balanced_pos_weight(dataset)\n",
    "    return dataset\n",
    "\n",
    "def IMDB_dataset(args=None) :\n",
    "    dataset = Dataset(name='imdb', path='preprocess/IMDB/vec_imdb.p', min_length=6, args=args)\n",
    "    set_balanced_pos_weight(dataset)\n",
    "    return dataset\n",
    "\n",
    "def News20_dataset(args=None) :\n",
    "    dataset = Dataset(name='20News_sports', path='preprocess/20News/vec_20news_sports.p', min_length=6, max_length=500, args=args)\n",
    "    set_balanced_pos_weight(dataset)\n",
    "    return dataset\n",
    "\n",
    "def ADR_dataset(args=None) :\n",
    "    dataset = Dataset(name='tweet', path='preprocess/Tweets/vec_adr.p', min_length=5, max_length=100, args=args)\n",
    "    set_balanced_pos_weight(dataset)\n",
    "    return dataset\n",
    "\n",
    "def Anemia_dataset(args=None) :\n",
    "    dataset = Dataset(name='anemia', path='preprocess/MIMIC/vec_anemia.p', max_length=4000, args=args)\n",
    "    set_balanced_pos_weight(dataset)\n",
    "    return dataset\n",
    "\n",
    "def Diabetes_dataset(args=None) :\n",
    "    dataset = Dataset(name='diabetes', path='preprocess/MIMIC/vec_diabetes.p', min_length=6, max_length=4000, args=args)\n",
    "    set_balanced_pos_weight(dataset)\n",
    "    return dataset\n",
    "\n",
    "def AGNews_dataset(args=None) :\n",
    "    dataset = Dataset(name='agnews', path='preprocess/ag_news/vec_agnews.p', args=args)\n",
    "    set_balanced_pos_weight(dataset)\n",
    "    return dataset\n",
    "\n",
    "datasets = {\n",
    "    \"sst\" : SST_dataset,\n",
    "    \"imdb\" : IMDB_dataset,\n",
    "    \"20News_sports\" : News20_dataset,\n",
    "    \"tweet\" : ADR_dataset ,\n",
    "    \"Anemia\" : Anemia_dataset,\n",
    "    \"Diabetes\" : Diabetes_dataset,\n",
    "    \"AgNews\" : AGNews_dataset\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets[args.dataset](args)\n",
    "\n",
    "if args.output_dir is not None :\n",
    "    dataset.output_dir = args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日志相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "\n",
    "def generate_config(dataset, args, exp_name) :\n",
    "\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "\n",
    "    if args.encoder == 'lstm' :\n",
    "        enc_type = 'rnn'\n",
    "    elif args.encoder == 'average' :\n",
    "        enc_type = args.encoder\n",
    "    else :\n",
    "        raise Exception(\"unknown encoder type\")\n",
    "\n",
    "    config = {\n",
    "        'model' :{\n",
    "            'encoder' : {\n",
    "                'vocab_size' : dataset.vec.vocab_size,\n",
    "                'embed_size' : dataset.vec.word_dim,\n",
    "\t\t'type' : enc_type,\n",
    "\t\t'hidden_size' : args.hidden_size\n",
    "            },\n",
    "            'decoder' : {\n",
    "                'attention' : {\n",
    "                    'type' : 'tanh'\n",
    "                },\n",
    "                'output_size' : dataset.output_size\n",
    "            }\n",
    "        },\n",
    "        'training' : {\n",
    "            'bsize' : dataset.bsize if hasattr(dataset, 'bsize') else 32,\n",
    "            'weight_decay' : 1e-5,\n",
    "            'pos_weight' : dataset.pos_weight if hasattr(dataset, 'pos_weight') else None,\n",
    "            'basepath' : dataset.basepath if hasattr(dataset, 'basepath') else 'outputs',\n",
    "            'exp_dirname' : os.path.join(dataset.name, exp_name)\n",
    "        },\n",
    "        'git_info' : {\n",
    "            'branch' : repo.active_branch.name,\n",
    "            'sha' : repo.head.object.hexsha\n",
    "        },\n",
    "        'command' : args.command\n",
    "    }\n",
    "\n",
    "    if args.encoder == 'average' :\n",
    "    \tconfig['model']['encoder'].update({'projection' : True, 'activation' : 'tanh'})\n",
    "\n",
    "    return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### Attention\n",
    "from torch import nn\n",
    "from allennlp.common import Registrable\n",
    "\n",
    "def masked_softmax(attn_odds, masks) :\n",
    "    attn_odds.masked_fill_(masks.bool(), -float('inf'))\n",
    "    attn = nn.Softmax(dim=-1)(attn_odds)\n",
    "    return attn\n",
    "\n",
    "class Attention(nn.Module, Registrable) :\n",
    "    def forward(self, **kwargs) :\n",
    "        raise NotImplementedError(\"Implement forward Model\")\n",
    "\n",
    "@Attention.register('tanh')\n",
    "class TanhAttention(Attention) :\n",
    "    def __init__(self, hidden_size) :\n",
    "        super().__init__()\n",
    "        self.attn1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.attn2 = nn.Linear(hidden_size // 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, input_seq, hidden, masks) :\n",
    "        #input_seq = (B, L), hidden : (B, L, H), masks : (B, L)\n",
    "\n",
    "        attn1 = nn.Tanh()(self.attn1(hidden)) #(B, L, H//2) #\n",
    "        attn2 = self.attn2(attn1).squeeze(-1) #(B, L)\n",
    "        attn = masked_softmax(attn2, masks) #(B, L)\n",
    "\n",
    "        return attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###### encoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from attention.model.modelUtils import isTrue\n",
    "from allennlp.common import Registrable\n",
    "from allennlp.nn.activations import Activation\n",
    "\n",
    "class Encoder(nn.Module, Registrable) :\n",
    "    def forward(self, **kwargs) :\n",
    "        raise NotImplementedError(\"Implement forward Model\")\n",
    "\n",
    "@Encoder.register('rnn')\n",
    "class EncoderRNN(Encoder) :\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, pre_embed=None) :\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        if pre_embed is not None :\n",
    "            print(\"Setting Embedding\")\n",
    "            weight = torch.Tensor(pre_embed)\n",
    "            weight[0, :].zero_()\n",
    "\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_size, _weight=weight, padding_idx=0)\n",
    "        else :\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.output_size = self.hidden_size * 2\n",
    "\n",
    "    def forward(self, data) :\n",
    "        seq = data.seq\n",
    "        lengths = data.lengths\n",
    "        embedding = self.embedding(seq) #(B, L, E)\n",
    "        packseq = nn.utils.rnn.pack_padded_sequence(embedding, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        output, (h, c) = self.rnn(packseq)\n",
    "        output, lengths = nn.utils.rnn.pad_packed_sequence(output, batch_first=True, padding_value=0) # [batch_size, seq_len, feature]\n",
    "\n",
    "        data.hidden = output\n",
    "        data.last_hidden = torch.cat([h[0], h[1]], dim=-1)\n",
    "\n",
    "        if isTrue(data, 'keep_grads') :\n",
    "            data.embedding = embedding\n",
    "            data.embedding.retain_grad()\n",
    "            data.hidden.retain_grad()\n",
    "\n",
    "\n",
    "@Encoder.register(\"average\")\n",
    "class EncoderAverage(Encoder) :\n",
    "    def __init__(self,  vocab_size, embed_size, projection, hidden_size=None, activation:Activation=Activation.by_name('linear'), pre_embed=None) :\n",
    "        super(EncoderAverage, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        if pre_embed is not None :\n",
    "            print(\"Setting Embedding\")\n",
    "            weight = torch.Tensor(pre_embed)\n",
    "            weight[0, :].zero_()\n",
    "\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_size, _weight=weight, padding_idx=0)\n",
    "        else :\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "\n",
    "        if projection :\n",
    "            self.projection = nn.Linear(embed_size, hidden_size)\n",
    "            self.output_size = hidden_size\n",
    "        else :\n",
    "            self.projection = lambda s : s\n",
    "            self.output_size = embed_size\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, data) :\n",
    "        seq = data.seq\n",
    "        lengths = data.lengths\n",
    "        embedding = self.embedding(seq) #(B, L, E)\n",
    "\n",
    "        output = self.activation(self.projection(embedding)) #(B, L, H)\n",
    "        h = output.mean(1) #(B, H)\n",
    "\n",
    "        data.hidden = output\n",
    "        data.last_hidden = h\n",
    "\n",
    "        if isTrue(data, 'keep_grads') :\n",
    "            data.embedding = embedding\n",
    "            data.embedding.retain_grad()\n",
    "            data.hidden.retain_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "####### decoder\n",
    "from allennlp.common.from_params import FromParams\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict\n",
    "from allennlp.common import Params\n",
    "\n",
    "# from attention.model.modules.Attention import Attention\n",
    "from attention.model.modelUtils import isTrue, BatchHolder\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AttnDecoder(nn.Module, FromParams) :\n",
    "    def __init__(self, hidden_size:int,\n",
    "                       attention:Dict,\n",
    "                       output_size:int = 1,\n",
    "                       use_attention:bool = True) :\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.linear_1 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        attention['hidden_size'] = self.hidden_size\n",
    "        self.attention = Attention.from_params(Params(attention))\n",
    "\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "    def decode(self, predict) :\n",
    "        predict = self.linear_1(predict)\n",
    "        return predict\n",
    "\n",
    "    def forward(self, data:BatchHolder, revise_att=None) :\n",
    "        if self.use_attention :\n",
    "            output = data.hidden\n",
    "            mask = data.masks\n",
    "\n",
    "            attn = self.attention(data.seq, output, mask) # (B, L)\n",
    "\n",
    "            if revise_att is not None:\n",
    "                attn = revise_att\n",
    "\n",
    "            context = (attn.unsqueeze(-1) * output).sum(1) # (B, H)\n",
    "            data.attn = attn\n",
    "        else :\n",
    "            context = data.last_hidden\n",
    "\n",
    "        predict = self.decode(context)\n",
    "        data.predict = predict\n",
    "\n",
    "\n",
    "class FrozenAttnDecoder(AttnDecoder) :\n",
    "\n",
    "    def forward(self, data:BatchHolder) :\n",
    "        if self.use_attention :\n",
    "            output = data.hidden\n",
    "            attn = data.generate_frozen_uniform_attn()\n",
    "\n",
    "            context = (attn.unsqueeze(-1) * output).sum(1)\n",
    "            data.attn = attn\n",
    "        else :\n",
    "            context = data.last_hidden\n",
    "\n",
    "        predict = self.decode(context)\n",
    "        data.predict = predict\n",
    "\n",
    "\n",
    "class PretrainedWeightsDecoder(AttnDecoder) :\n",
    "\n",
    "    def forward(self, data:BatchHolder) :\n",
    "        if self.use_attention :\n",
    "            output = data.hidden\n",
    "            attn = data.target_attn\n",
    "\n",
    "            context = (attn.unsqueeze(-1) * output).sum(1)\n",
    "            data.attn = attn\n",
    "        else :\n",
    "            context = data.last_hidden\n",
    "\n",
    "        predict = self.decode(context)\n",
    "        data.predict = predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 训练controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "from pandas.io.json.normalize import nested_to_record\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "def tvd(predictions, targets): #accepts two numpy arrays of dimension: (num. instances, )\n",
    "    return (0.5 * np.abs(predictions - targets)).sum()\n",
    "\n",
    "def batch_tvd(predictions, targets): #accepts two Torch tensors... \" \"\n",
    "    return (0.5 * torch.abs(predictions - targets)).sum()\n",
    "\n",
    "def calc_metrics_classification(target, predictions, target_scores=None, jsd_score=None) :\n",
    "\n",
    "    if target_scores is not None :\n",
    "        assert predictions.squeeze(1).shape == target_scores.shape\n",
    "        tvdist = tvd(predictions.squeeze(1), target_scores)\n",
    "\n",
    "    if predictions.shape[-1] == 1 :\n",
    "        predictions = predictions[:, 0]\n",
    "        predictions = np.array([1 - predictions, predictions]).T\n",
    "\n",
    "    predict_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    if len(np.unique(target)) < 4 :\n",
    "        rep = nested_to_record(classification_report(target, predict_classes, output_dict=True), sep='/')\n",
    "    else :\n",
    "        rep = {}\n",
    "    rep.update({'accuracy' : accuracy_score(target, predict_classes)})\n",
    "\n",
    "    if jsd_score :\n",
    "        rep.update({'js_divergence' : jsd_score})\n",
    "    if target_scores is not None :\n",
    "        rep.update({'TVD' : tvdist})\n",
    "\n",
    "    if predictions.shape[-1] == 2 :\n",
    "        rep.update({'roc_auc' : roc_auc_score(target, predictions[:, 1])})\n",
    "        rep.update({\"pr_auc\" : average_precision_score(target, predictions[:, 1])})\n",
    "    return rep\n",
    "\n",
    "def print_metrics(metrics, adv=False) :\n",
    "    tabular = {k:v for k, v in metrics.items() if '/' in k}\n",
    "    non_tabular = {k:v for k, v in metrics.items() if '/' not in k}\n",
    "    print(non_tabular)\n",
    "\n",
    "    d = defaultdict(dict)\n",
    "    for k, v in tabular.items() :\n",
    "        if not k.startswith('label_') :\n",
    "            d[k.split('/', 1)[0]][k.split('/', 1)[1]] = v\n",
    "        if '/1/' in k or 'auc' in k:\n",
    "            d[k.split('/', 1)[0]][k.split('/', 1)[1]] = v\n",
    "\n",
    "    df = pd.DataFrame(d)\n",
    "    with pd.option_context('display.max_columns', 30):\n",
    "        display(df.round(3))\n",
    "\n",
    "    if adv :\n",
    "        print(\"TVD:\", metrics['TVD'])\n",
    "        print(\"JS:\", metrics['js_divergence'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from allennlp.common import Params\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# from attention.model.modules.Decoder import AttnDecoder, FrozenAttnDecoder, PretrainedWeightsDecoder\n",
    "# from attention.model.modules.Encoder import Encoder\n",
    "# from attention.common_code.metrics import batch_tvd\n",
    "\n",
    "from attention.model.modelUtils import BatchHolder, get_sorting_index_with_noise_from_lengths\n",
    "from attention.model.modelUtils import jsd as js_divergence\n",
    "\n",
    "# file_name = os.path.abspath(__file__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class BC_Model():\n",
    "    def __init__(self, configuration, args, pre_embed=None):\n",
    "        configuration = deepcopy(configuration)\n",
    "        self.configuration = deepcopy(configuration)\n",
    "\n",
    "        configuration['model']['encoder']['pre_embed'] = pre_embed\n",
    "        self.encoder = Encoder.from_params(\n",
    "            Params(configuration['model']['encoder'])).to(device)\n",
    "\n",
    "        self.frozen_attn = args.frozen_attn\n",
    "        self.adversarial = args.adversarial\n",
    "        self.pre_loaded_attn = args.pre_loaded_attn\n",
    "\n",
    "        configuration['model']['decoder'][\n",
    "            'hidden_size'] = self.encoder.output_size\n",
    "        if self.frozen_attn:\n",
    "            self.decoder = FrozenAttnDecoder.from_params(\n",
    "                Params(configuration['model']['decoder'])).to(device)\n",
    "        elif self.pre_loaded_attn:\n",
    "            self.decoder = PretrainedWeightsDecoder.from_params(\n",
    "                Params(configuration['model']['decoder'])).to(device)\n",
    "        else:\n",
    "            self.decoder = AttnDecoder.from_params(\n",
    "                Params(configuration['model']['decoder'])).to(device)\n",
    "\n",
    "        self.encoder_params = list(self.encoder.parameters())\n",
    "        if not self.frozen_attn:\n",
    "            self.attn_params = list([\n",
    "                v for k, v in self.decoder.named_parameters()\n",
    "                if 'attention' in k\n",
    "            ])\n",
    "        self.decoder_params = list([\n",
    "            v for k, v in self.decoder.named_parameters()\n",
    "            if 'attention' not in k\n",
    "        ])\n",
    "\n",
    "        self.bsize = configuration['training']['bsize']\n",
    "\n",
    "        weight_decay = configuration['training'].get('weight_decay', 1e-5)\n",
    "        self.encoder_optim = torch.optim.Adam(\n",
    "            self.encoder_params,\n",
    "            lr=0.001,\n",
    "            weight_decay=weight_decay,\n",
    "            amsgrad=True)\n",
    "        if not self.frozen_attn:\n",
    "            self.attn_optim = torch.optim.Adam(\n",
    "                self.attn_params, lr=0.001, weight_decay=0, amsgrad=True)\n",
    "        self.decoder_optim = torch.optim.Adam(\n",
    "            self.decoder_params,\n",
    "            lr=0.001,\n",
    "            weight_decay=weight_decay,\n",
    "            amsgrad=True)\n",
    "\n",
    "        pos_weight = configuration['training'].get(\n",
    "            'pos_weight', [1.0] * self.decoder.output_size)\n",
    "        self.pos_weight = torch.Tensor(pos_weight).to(device)\n",
    "\n",
    "        # setup either adversarial or std binary cross-entropy loss\n",
    "        if self.adversarial:\n",
    "            self.criterion = nn.KLDivLoss(\n",
    "                size_average=None, reduce=None, reduction='sum').to(device)\n",
    "            self.lmbda = args.lmbda\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(reduction='none').to(device)\n",
    "\n",
    "        dirname = configuration['training']['exp_dirname']\n",
    "        basepath = configuration['training'].get('basepath', 'outputs')\n",
    "        self.time_str = time.ctime().replace(' ', '_')\n",
    "        self.dirname = os.path.join(basepath, dirname, self.time_str)\n",
    "\n",
    "        self.lambda_1 = args.lambda_1\n",
    "        self.lambda_2 = args.lambda_2\n",
    "\n",
    "\n",
    "        self.K = args.K\n",
    "        self.topk_prox_metric = args.topk_prox_metric\n",
    "\n",
    "    @classmethod\n",
    "    def init_from_config(cls, dirname, args, **kwargs):\n",
    "        config = json.load(open(dirname + '/config.json', 'r'))\n",
    "        config.update(kwargs)\n",
    "        obj = cls(config, args)\n",
    "        obj.load_values(dirname)\n",
    "        return obj\n",
    "\n",
    "    def train_ours(self,\n",
    "              data_in,\n",
    "              target_in,\n",
    "              target_pred,\n",
    "              target_attn_in,\n",
    "              PGDer,train=True):\n",
    "        sorting_idx = get_sorting_index_with_noise_from_lengths(\n",
    "            [len(x) for x in data_in], noise_frac=0.1)\n",
    "        data = [data_in[i] for i in sorting_idx]\n",
    "        target = [target_in[i] for i in sorting_idx]\n",
    "\n",
    "        # print(target_pred)\n",
    "\n",
    "        target_pred = [target_pred[i] for i in sorting_idx]\n",
    "        target_attn = [target_attn_in[i] for i in sorting_idx]\n",
    "\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "\n",
    "        from attention.utlis import AverageMeter\n",
    "\n",
    "        bsize = self.bsize\n",
    "        N = len(data)\n",
    "        loss_total = 0\n",
    "        loss_orig_total = 0\n",
    "        tvd_loss_total = 0\n",
    "        topk_loss_total = 0\n",
    "        pgd_tvd_loss_total = 0\n",
    "        true_topk_loss_counter = AverageMeter()\n",
    "\n",
    "        batches = list(range(0, N, bsize))\n",
    "        batches = shuffle(batches)\n",
    "\n",
    "        for n in tqdm(batches):\n",
    "            batch_doc = data[n:n + bsize]\n",
    "\n",
    "            batch_target_attn = target_attn[n:n + bsize]\n",
    "            batch_data = BatchHolder(batch_doc, batch_target_attn)\n",
    "\n",
    "            batch_target_pred = target_pred[n:n + bsize]\n",
    "            batch_target_pred = torch.Tensor(batch_target_pred).to(device)\n",
    "\n",
    "            if len(batch_target_pred.shape) == 1:  # (B, )\n",
    "                batch_target_pred = batch_target_pred.unsqueeze(\n",
    "                    -1)  # (B, 1)\n",
    "\n",
    "            self.encoder(batch_data)\n",
    "            self.decoder(batch_data)\n",
    "\n",
    "            batch_target = target[n:n + bsize]\n",
    "            batch_target = torch.Tensor(batch_target).to(device)\n",
    "\n",
    "            if len(batch_target.shape) == 1:  #(B, )\n",
    "                batch_target = batch_target.unsqueeze(-1)  #(B, 1)\n",
    "\n",
    "            # calculate adversarial loss (Section 4) if adversarial model\n",
    "\n",
    "            from attention.utlis import topk_overlap_loss,topK_overlap_true_loss\n",
    "            topk_loss = topk_overlap_loss(batch_data.target_attn,\n",
    "                                          batch_data.attn,K=self.K, metric=self.topk_prox_metric)\n",
    "            topk_true_loss = topK_overlap_true_loss(batch_data.target_attn,\n",
    "                                          batch_data.attn,K=self.K)\n",
    "            true_topk_loss_counter.update(\n",
    "                topk_true_loss,len(batch_doc)\n",
    "            )\n",
    "\n",
    "            tvd_loss = batch_tvd(\n",
    "                torch.sigmoid(batch_data.predict), batch_target_pred)\n",
    "\n",
    "            ### pgd loss\n",
    "            def target_model(w, data, decoder):\n",
    "                decoder(revise_att=w, data=data)\n",
    "                return data.predict\n",
    "\n",
    "            def crit(gt, pred):\n",
    "                return batch_tvd(torch.sigmoid(pred), gt)\n",
    "\n",
    "            # PGD generate the new weight\n",
    "            new_att = PGDer.perturb(criterion=crit, att=batch_data.attn, data=batch_data \\\n",
    "                                    , decoder=self.decoder, batch_target_pred=batch_target_pred,\n",
    "                                    target_model=target_model)\n",
    "\n",
    "            # output the prediction tvd of new weight and old weight\n",
    "            self.decoder(batch_data, revise_att=new_att)\n",
    "            new_out = batch_data.predict\n",
    "            att_pgd_pred_tvd = batch_tvd(\n",
    "                torch.sigmoid(new_out), batch_target_pred)\n",
    "\n",
    "            loss_orig = tvd_loss + self.lambda_1 * att_pgd_pred_tvd + self.lambda_2 * topk_loss\n",
    "\n",
    "\n",
    "            weight = batch_target * self.pos_weight + (1 - batch_target)\n",
    "            loss = (loss_orig * weight).mean(1).sum()\n",
    "\n",
    "            if hasattr(batch_data, 'reg_loss'):\n",
    "                loss += batch_data.reg_loss\n",
    "\n",
    "            if train:\n",
    "                self.encoder_optim.zero_grad()\n",
    "                self.decoder_optim.zero_grad()\n",
    "                if not self.frozen_attn:\n",
    "                    self.attn_optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.encoder_optim.step()\n",
    "                self.decoder_optim.step()\n",
    "                if not self.frozen_attn:\n",
    "                    self.attn_optim.step()\n",
    "\n",
    "            loss_total += float(loss.data.cpu().item())\n",
    "            loss_orig_total += float(loss_orig.data.cpu().item())\n",
    "            tvd_loss_total += float(tvd_loss.data.cpu().item())\n",
    "            topk_loss_total += float(topk_loss.data.cpu().item())\n",
    "            pgd_tvd_loss_total += float(\n",
    "                att_pgd_pred_tvd.data.cpu().item())\n",
    "\n",
    "        return  loss_total, loss_orig_total, tvd_loss_total, topk_loss_total, pgd_tvd_loss_total, true_topk_loss_counter.average()\n",
    "\n",
    "    def train(self,\n",
    "              data_in,\n",
    "              target_in,\n",
    "              target_pred=None,\n",
    "              target_attn_in=None,\n",
    "              train=True,\n",
    "              ours=False,\n",
    "              PDGer=None):\n",
    "        sorting_idx = get_sorting_index_with_noise_from_lengths(\n",
    "            [len(x) for x in data_in], noise_frac=0.1)\n",
    "        data = [data_in[i] for i in sorting_idx]\n",
    "        target = [target_in[i] for i in sorting_idx]\n",
    "\n",
    "        if target_pred:\n",
    "            target_pred = [target_pred[i] for i in sorting_idx]\n",
    "            target_attn = [target_attn_in[i] for i in sorting_idx]\n",
    "\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        bsize = self.bsize\n",
    "        N = len(data)\n",
    "        loss_total = 0\n",
    "        loss_orig_total = 0\n",
    "        tvd_loss_total = 0\n",
    "        kl_loss_total = 0\n",
    "        topk_loss_total = 0\n",
    "        pgd_tvd_loss_total = 0\n",
    "\n",
    "        batches = list(range(0, N, bsize))\n",
    "        batches = shuffle(batches)\n",
    "\n",
    "        for n in tqdm(batches):\n",
    "            batch_doc = data[n:n + bsize]\n",
    "            if target_pred:\n",
    "                batch_target_attn = target_attn[n:n + bsize]\n",
    "                batch_data = BatchHolder(batch_doc, batch_target_attn)\n",
    "\n",
    "                batch_target_pred = target_pred[n:n + bsize]\n",
    "                batch_target_pred = torch.Tensor(batch_target_pred).to(device)\n",
    "\n",
    "                if len(batch_target_pred.shape) == 1:  #(B, )\n",
    "                    batch_target_pred = batch_target_pred.unsqueeze(\n",
    "                        -1)  #(B, 1)\n",
    "            else:\n",
    "                batch_data = BatchHolder(batch_doc)\n",
    "\n",
    "            self.encoder(batch_data)\n",
    "            self.decoder(batch_data)\n",
    "\n",
    "            batch_target = target[n:n + bsize]\n",
    "            batch_target = torch.Tensor(batch_target).to(device)\n",
    "\n",
    "            if len(batch_target.shape) == 1:  #(B, )\n",
    "                batch_target = batch_target.unsqueeze(-1)  #(B, 1)\n",
    "\n",
    "            # calculate adversarial loss (Section 4) if adversarial model\n",
    "            if target_pred:\n",
    "                # if ours:\n",
    "                #     from attention.utlis import topk_overlap_loss\n",
    "                #     topk_loss = topk_overlap_loss(batch_data.target_attn.log(),\n",
    "                #                                   batch_data.attn)\n",
    "                #     tvd_loss = batch_tvd(\n",
    "                #         torch.sigmoid(batch_data.predict), batch_target_pred)\n",
    "                #\n",
    "                #     ### pgd loss\n",
    "                #     def target_model(w, data, decoder):\n",
    "                #         decoder(revise_att=w, data=data)\n",
    "                #         return data.predict\n",
    "                #\n",
    "                #     def crit(gt, pred):\n",
    "                #         return batch_tvd(torch.sigmoid(pred), gt)\n",
    "                #\n",
    "                #     # PGD generate the new weight\n",
    "                #     new_att = PDGer.perturb(criterion=crit, att=batch_data.attn, data=batch_data \\\n",
    "                #                           , decoder=self.decoder,batch_target_pred=batch_target_pred, target_model=target_model)\n",
    "                #\n",
    "                #     # output the prediction tvd of new weight and old weight\n",
    "                #     self.decoder(batch_data, revise_att=new_att)\n",
    "                #     new_out = batch_data.predict\n",
    "                #     att_pgd_pred_tvd = batch_tvd(\n",
    "                #         torch.sigmoid(new_out), batch_target_pred)\n",
    "                #\n",
    "                #     loss_orig = tvd_loss + self.lambda_1 * att_pgd_pred_tvd + self.lambda_2 * topk_loss\n",
    "                #\n",
    "                # else:\n",
    "                kl_loss = self.criterion(batch_data.target_attn.log(),\n",
    "                                         batch_data.attn)\n",
    "                tvd_loss = batch_tvd(\n",
    "                    torch.sigmoid(batch_data.predict), batch_target_pred)\n",
    "                loss_orig = tvd_loss - self.lmbda * kl_loss\n",
    "\n",
    "            # else calculate standard BCE loss\n",
    "            else:\n",
    "                loss_orig = self.criterion(batch_data.predict, batch_target)\n",
    "\n",
    "            weight = batch_target * self.pos_weight + (1 - batch_target)\n",
    "            loss = (loss_orig * weight).mean(1).sum()\n",
    "\n",
    "            if hasattr(batch_data, 'reg_loss'):\n",
    "                loss += batch_data.reg_loss\n",
    "\n",
    "            if train:\n",
    "                self.encoder_optim.zero_grad()\n",
    "                self.decoder_optim.zero_grad()\n",
    "                if not self.frozen_attn:\n",
    "                    self.attn_optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.encoder_optim.step()\n",
    "                self.decoder_optim.step()\n",
    "                if not self.frozen_attn:\n",
    "                    self.attn_optim.step()\n",
    "\n",
    "            loss_total += float(loss.data.cpu().item())\n",
    "\n",
    "            if target_attn_in:\n",
    "                # if ours:\n",
    "                #     loss_orig_total += float(loss_orig.data.cpu().item())\n",
    "                #     tvd_loss_total += float(tvd_loss.data.cpu().item())\n",
    "                #     # kl_loss_total += float(kl_loss.data.cpu().item())\n",
    "                #     topk_loss_total += float(topk_loss.data.cpu().item())\n",
    "                #     pgd_tvd_loss_total += float(\n",
    "                #         att_pgd_pred_tvd.data.cpu().item())\n",
    "                # else:\n",
    "\n",
    "                loss_orig_total += float(loss_orig.data.cpu().item())\n",
    "                tvd_loss_total += float(tvd_loss.data.cpu().item())\n",
    "                kl_loss_total += float(kl_loss.data.cpu().item())\n",
    "        # if ours:\n",
    "        #     return loss_total * bsize / N, loss_total, loss_orig_total, tvd_loss_total, topk_loss_total, pgd_tvd_loss_total\n",
    "        # else:\n",
    "        #     return loss_total * bsize / N, loss_total, loss_orig_total, tvd_loss_total, kl_loss_total\n",
    "        return loss_total * bsize / N, loss_total, loss_orig_total, tvd_loss_total, kl_loss_total\n",
    "\n",
    "    def evaluate(self, data, target_attn=None):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        bsize = self.bsize\n",
    "        N = len(data)\n",
    "\n",
    "        outputs = []\n",
    "        attns = []\n",
    "        js_scores = []\n",
    "\n",
    "        for n in tqdm(range(0, N, bsize)):\n",
    "            batch_doc = data[n:n + bsize]\n",
    "            if target_attn:\n",
    "                batch_target_attn = target_attn[n:n + bsize]\n",
    "                batch_data = BatchHolder(batch_doc, batch_target_attn)\n",
    "            else:\n",
    "                batch_data = BatchHolder(batch_doc)\n",
    "\n",
    "            self.encoder(batch_data)\n",
    "            self.decoder(batch_data)\n",
    "\n",
    "            batch_data.predict = torch.sigmoid(batch_data.predict)\n",
    "            if self.decoder.use_attention:  #and n == 0:\n",
    "                attn = batch_data.attn.cpu().data.numpy()  #.astype('float16')\n",
    "                attns.append(attn)\n",
    "\n",
    "            predict = batch_data.predict.cpu().data.numpy(\n",
    "            )  #.astype('float16')\n",
    "            outputs.append(predict)\n",
    "\n",
    "            if target_attn:\n",
    "                #compute JS-divergence for batched attentions\n",
    "                batch_jsdscores = js_divergence(\n",
    "                    batch_data.target_attn, batch_data.attn).squeeze(\n",
    "                        1).cpu().data.numpy()  #.astype('float16')\n",
    "                js_scores.append(batch_jsdscores)\n",
    "\n",
    "        outputs = [x for y in outputs for x in y]\n",
    "        if self.decoder.use_attention:\n",
    "            attns = [x for y in attns for x in y]\n",
    "        if target_attn:\n",
    "            js_score = sum([x for y in js_scores for x in y]).item()\n",
    "        else:\n",
    "            js_score = None\n",
    "\n",
    "        return outputs, attns, js_score\n",
    "\n",
    "    def save_values(self, use_dirname=None, save_model=True):\n",
    "        if use_dirname is not None:\n",
    "            dirname = use_dirname\n",
    "        else:\n",
    "            dirname = self.dirname\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "        # shutil.copy2(file_name, dirname + '/')\n",
    "        json.dump(self.configuration, open(dirname + '/config.json', 'w'))\n",
    "\n",
    "        if save_model:\n",
    "            torch.save(self.encoder.state_dict(), dirname + '/enc.th')\n",
    "            torch.save(self.decoder.state_dict(), dirname + '/dec.th')\n",
    "\n",
    "        return dirname\n",
    "\n",
    "    def load_values(self, dirname):\n",
    "        self.encoder.load_state_dict(\n",
    "            torch.load(dirname + '/enc.th', map_location={'cuda:1': 'cuda:0'}))\n",
    "        self.decoder.load_state_dict(\n",
    "            torch.load(dirname + '/dec.th', map_location={'cuda:1': 'cuda:0'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from attention.common_code.metrics import calc_metrics_classification, print_metrics\n",
    "# import attention.model.Binary_Classification as BC\n",
    "import codecs, json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from attention.preprocess import vectorizer\n",
    "# import wandb\n",
    "\n",
    "class Trainer() :\n",
    "    def __init__(self, dataset, args, config) :\n",
    "        Model = BC_Model\n",
    "        self.model = Model(config, args, pre_embed=dataset.vec.embeddings)\n",
    "        self.metrics = calc_metrics_classification\n",
    "        self.display_metrics = True\n",
    "        self.PGDer = None\n",
    "\n",
    "    def train_standard(self, train_data, test_data, args, save_on_metric='roc_auc') :\n",
    "\n",
    "        best_metric = 0.0\n",
    "        for i in tqdm(range(args.n_iters)) :\n",
    "\n",
    "            _, loss_tr, loss_tr_orig, _, _ = self.model.train(train_data.X, train_data.y)\n",
    "            predictions_tr, attentions_tr, _ = self.model.evaluate(train_data.X)\n",
    "            predictions_tr = np.array(predictions_tr)\n",
    "            train_metrics = self.metrics(np.array(train_data.y), predictions_tr)\n",
    "            print_str = \"FULL (WEIGHTED) LOSS: %f | ORIG (UNWEIGHTED) LOSS: %f\" % (loss_tr, loss_tr_orig)\n",
    "            print(print_str)\n",
    "\n",
    "            print(\"TRAIN METRICS:\")\n",
    "            if self.display_metrics:\n",
    "                print_metrics(train_metrics, adv=False)\n",
    "\n",
    "            predictions_te, attentions_te, _ = self.model.evaluate(test_data.X)\n",
    "            predictions_te = np.array(predictions_te)\n",
    "            test_metrics = self.metrics(np.array(test_data.y), predictions_te)\n",
    "\n",
    "            print(\"TEST METRICS:\")\n",
    "            if self.display_metrics:\n",
    "                print_metrics(test_metrics, adv=False)\n",
    "\n",
    "            metric = test_metrics[save_on_metric]\n",
    "            if metric > best_metric :\n",
    "                best_metric = metric\n",
    "                save_model = True\n",
    "                print(\"Model Saved on \", save_on_metric, metric)\n",
    "            else :\n",
    "                save_model = False\n",
    "                print(\"Model not saved on \", save_on_metric, metric)\n",
    "\n",
    "            dirname = self.model.save_values(save_model=save_model)\n",
    "            if save_model:\n",
    "                attentions_tr = [el.tolist() for el in attentions_tr]\n",
    "                attentions_te = [el.tolist() for el in attentions_te]\n",
    "                print(\"SAVING PREDICTIONS AND ATTENTIONS\")\n",
    "                json.dump(predictions_tr.tolist(), codecs.open(dirname + '/train_predictions_best_epoch.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(predictions_te.tolist(), codecs.open(dirname + '/test_predictions_best_epoch.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(attentions_tr, codecs.open(dirname + '/train_attentions_best_epoch.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(attentions_te, codecs.open(dirname + '/test_attentions_best_epoch.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "\n",
    "            print(\"DIRECTORY:\", dirname)\n",
    "\n",
    "            f = open(dirname + '/epoch.txt', 'a')\n",
    "            f.write(str(test_metrics) + '\\n')\n",
    "            f.close()\n",
    "\n",
    "    def train_ours(self, train_data, test_data, args):\n",
    "        br = False\n",
    "        n_fail = 0\n",
    "        best_loss = 10000000000\n",
    "        for i in tqdm(range(args.n_iters)):\n",
    "\n",
    "            loss_tr, loss_tr_orig, tvd_loss_tr, topk_loss_tr, pgd_tvd_loss_tr,true_topk_loss_tr = self.model.train_ours(train_data.X, train_data.y,\n",
    "                                                                                 train_data.true_pred,\n",
    "                                                                                 train_data.gold_attns,PGDer=self.PGDer)\n",
    "            # wandb.log({\n",
    "            #     \"loss_tr\":loss_tr,\n",
    "            #     \"loss_tr_orig\":loss_tr_orig,\n",
    "            #     \"tvd_loss_tr\":tvd_loss_tr,\n",
    "            #     \"topk_loss_tr\":topk_loss_tr,\n",
    "            #     \"pgd_tvd_loss_tr\":pgd_tvd_loss_tr,\n",
    "            #     \"true_topk_loss_tr\":true_topk_loss_tr\n",
    "            # })\n",
    "\n",
    "            loss_te, loss_te_orig, tvd_loss_te, topk_loss_te, pgd_tvd_loss_te, true_topk_loss_te = self.model.train_ours(test_data.X,\n",
    "                                                                                                test_data.y,\n",
    "                                                                                                test_data.true_pred,\n",
    "                                                                                                test_data.gold_attns,\n",
    "                                                                                                PGDer=self.PGDer, train=False)\n",
    "            # wandb.log({\n",
    "            #     \"loss_te\": loss_te,\n",
    "            #     \"loss_te_orig\": loss_te_orig,\n",
    "            #     \"tvd_loss_te\": tvd_loss_te,\n",
    "            #     \"topk_loss_te\": topk_loss_te,\n",
    "            #     \"pgd_tvd_loss_te\": pgd_tvd_loss_te,\n",
    "            #     \"true_topk_loss_te\":true_topk_loss_te\n",
    "            # })\n",
    "\n",
    "            predictions_tr, attentions_tr, jsd_score_tr = self.model.evaluate(train_data.X,\n",
    "                                                                              target_attn=train_data.gold_attns)\n",
    "\n",
    "            # wandb.log({\n",
    "            #     \"predictions_tr\": predictions_tr,\n",
    "            #     \"attentions_tr\": attentions_tr,\n",
    "            #     \"jsd_score_tr\": jsd_score_tr,\n",
    "            # })\n",
    "\n",
    "            predictions_tr = np.array(predictions_tr)\n",
    "            train_metrics = self.metrics(np.array(train_data.y), predictions_tr, np.array(train_data.true_pred),\n",
    "                                         jsd_score_tr)\n",
    "            print_str = \"FULL (WEIGHTED) LOSS: %f | ORIG (UNWEIGHTED) LOSS: %f | TOPK-LOSS: %f | TVD-OUT: %f | TVD-PGD: %f\" % (\n",
    "            loss_tr, loss_tr_orig, topk_loss_tr, tvd_loss_tr, pgd_tvd_loss_tr)\n",
    "            # print(print_str)\n",
    "            #\n",
    "            # print(\"TRAIN METRICS:\")\n",
    "            # if self.display_metrics:\n",
    "            #     print_metrics(train_metrics, adv=True)\n",
    "            #\n",
    "            predictions_te, attentions_te, jsd_score_te = self.model.evaluate(test_data.X,\n",
    "                                                                              target_attn=test_data.gold_attns)\n",
    "            # wandb.log({\n",
    "            #     \"predictions_te\": predictions_te,\n",
    "            #     \"attentions_te\": attentions_te,\n",
    "            #     \"jsd_score_te\": jsd_score_te,\n",
    "            # })\n",
    "\n",
    "            predictions_te = np.array(predictions_te)\n",
    "            test_metrics = self.metrics(np.array(test_data.y), predictions_te, np.array(test_data.true_pred),\n",
    "                                        jsd_score_te)\n",
    "\n",
    "            # print(\"TEST METRICS:\")\n",
    "            # if self.display_metrics:\n",
    "            #     print_metrics(test_metrics, adv=True)\n",
    "\n",
    "            if loss_tr < best_loss:\n",
    "                best_loss = loss_tr\n",
    "                n_fail = 0\n",
    "                save_model = True\n",
    "                # print(\"Model Saved on Training Loss: \", loss_tr)\n",
    "                # wandb.log({\n",
    "                #     \"best_loss\": best_loss,\n",
    "                # })\n",
    "\n",
    "            else:\n",
    "                n_fail += 1\n",
    "                save_model = False\n",
    "                # print(\"Model not saved on Training Loss: \", loss_tr)\n",
    "                if n_fail >= 10:\n",
    "                    br = True\n",
    "                    # print(\"Loss hasn't decreased for 10 epochs...EARLY STOPPING TRIGGERED\")\n",
    "\n",
    "            dirname = self.model.save_values(save_model=save_model)\n",
    "            if save_model:\n",
    "                attentions_tr = [el.tolist() for el in attentions_tr]\n",
    "                attentions_te = [el.tolist() for el in attentions_te]\n",
    "                # print(\"SAVING PREDICTIONS AND ATTENTIONS\")\n",
    "                json.dump(predictions_tr.tolist(),\n",
    "                          codecs.open(dirname + '/train_predictions_best_epoch.json', 'w', encoding='utf-8'),\n",
    "                          separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(predictions_te.tolist(),\n",
    "                          codecs.open(dirname + '/test_predictions_best_epoch.json', 'w', encoding='utf-8'),\n",
    "                          separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(attentions_tr,\n",
    "                          codecs.open(dirname + '/train_attentions_best_epoch.json', 'w', encoding='utf-8'),\n",
    "                          separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(attentions_te,\n",
    "                          codecs.open(dirname + '/test_attentions_best_epoch.json', 'w', encoding='utf-8'),\n",
    "                          separators=(',', ':'), sort_keys=True, indent=4)\n",
    "\n",
    "            print(\"DIRECTORY:\", dirname)\n",
    "\n",
    "            f = open(dirname + '/epoch.txt', 'a')\n",
    "            f.write(str(test_metrics) + '\\n')\n",
    "            f.close()\n",
    "\n",
    "            f = open(dirname + '/losses.txt', 'a')\n",
    "            f.write(\"EPOCH %d: \" % i + print_str + '\\n')\n",
    "            f.close()\n",
    "\n",
    "            if br:\n",
    "                break\n",
    "\n",
    "    def train_adversarial(self, train_data, test_data, args) :\n",
    "\n",
    "        br = False\n",
    "        n_fail = 0\n",
    "        best_loss = 10000000000\n",
    "        for i in tqdm(range(args.n_iters)) :\n",
    "\n",
    "            _, loss_tr, loss_tr_orig, tvd_loss_tr, kl_loss_tr = self.model.train(train_data.X, train_data.y, train_data.true_pred, train_data.gold_attns)\n",
    "            predictions_tr, attentions_tr, jsd_score_tr = self.model.evaluate(train_data.X, target_attn=train_data.gold_attns)\n",
    "            predictions_tr = np.array(predictions_tr)\n",
    "            train_metrics = self.metrics(np.array(train_data.y), predictions_tr, np.array(train_data.true_pred), jsd_score_tr)\n",
    "            print_str = \"FULL (WEIGHTED) LOSS: %f | ORIG (UNWEIGHTED) LOSS: %f | KL: %f | TVD: %f\" % (loss_tr, loss_tr_orig, kl_loss_tr, tvd_loss_tr)\n",
    "            print(print_str)\n",
    "\n",
    "            print(\"TRAIN METRICS:\")\n",
    "            if self.display_metrics:\n",
    "                print_metrics(train_metrics, adv=True)\n",
    "\n",
    "            predictions_te, attentions_te, jsd_score_te = self.model.evaluate(test_data.X, target_attn=test_data.gold_attns)\n",
    "            predictions_te = np.array(predictions_te)\n",
    "            test_metrics = self.metrics(np.array(test_data.y), predictions_te, np.array(test_data.true_pred), jsd_score_te)\n",
    "\n",
    "            print(\"TEST METRICS:\")\n",
    "            if self.display_metrics:\n",
    "                print_metrics(test_metrics, adv=True)\n",
    "\n",
    "            if loss_tr < best_loss:\n",
    "                best_loss = loss_tr\n",
    "                n_fail = 0\n",
    "                save_model = True\n",
    "                print(\"Model Saved on Training Loss: \", loss_tr)\n",
    "\n",
    "            else :\n",
    "                n_fail += 1\n",
    "                save_model = False\n",
    "                print(\"Model not saved on Training Loss: \", loss_tr)\n",
    "                if n_fail >= 10:\n",
    "                    br = True\n",
    "                    print(\"Loss hasn't decreased for 10 epochs...EARLY STOPPING TRIGGERED\")\n",
    "\n",
    "            dirname = self.model.save_values(save_model=save_model)\n",
    "            if save_model:\n",
    "                attentions_tr = [el.tolist() for el in attentions_tr]\n",
    "                attentions_te = [el.tolist() for el in attentions_te]\n",
    "                print(\"SAVING PREDICTIONS AND ATTENTIONS\")\n",
    "                json.dump(predictions_tr.tolist(), codecs.open(dirname + '/train_predictions_best_epoch.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(predictions_te.tolist(), codecs.open(dirname + '/test_predictions_best_epoch.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(attentions_tr, codecs.open(dirname + '/train_attentions_best_epoch.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "                json.dump(attentions_te, codecs.open(dirname + '/test_attentions_best_epoch.json', 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "\n",
    "            print(\"DIRECTORY:\", dirname)\n",
    "\n",
    "            f = open(dirname + '/epoch.txt', 'a')\n",
    "            f.write(str(test_metrics) + '\\n')\n",
    "            f.close()\n",
    "\n",
    "            f = open(dirname + '/losses.txt', 'a')\n",
    "            f.write(\"EPOCH %d: \" % i + print_str + '\\n')\n",
    "            f.close()\n",
    "\n",
    "            if br:\n",
    "                break\n",
    "\n",
    "class Evaluator() :\n",
    "    def __init__(self, dataset, dirname, args) :\n",
    "        Model = BC_Model\n",
    "        self.model = Model.init_from_config(dirname, args)\n",
    "        self.model.dirname = dirname\n",
    "        self.metrics = calc_metrics_classification\n",
    "        self.display_metrics = True\n",
    "\n",
    "    def evaluate(self, test_data, save_results=False) :\n",
    "        if self.model.adversarial :\n",
    "            predictions, attentions, jsd_score = self.model.evaluate(test_data.X, target_attn=test_data.gold_attns)\n",
    "            predictions = np.array(predictions)\n",
    "            test_metrics = self.metrics(np.array(test_data.y), predictions, np.array(test_data.true_pred), jsd_score)\n",
    "        else :\n",
    "            predictions, attentions, _ = self.model.evaluate(test_data.X)\n",
    "            predictions = np.array(predictions)\n",
    "            test_metrics = self.metrics(test_data.y, predictions)\n",
    "\n",
    "        if self.display_metrics :\n",
    "            print_metrics(test_metrics, adv=self.model.adversarial)\n",
    "\n",
    "        if save_results :\n",
    "            f = open(self.model.dirname + '/evaluate.json', 'w')\n",
    "            json.dump(test_metrics, f)\n",
    "            f.close()\n",
    "\n",
    "        test_data.yt_hat = predictions\n",
    "        test_data.attn_hat = attentions\n",
    "        return predictions, attentions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/envs/xai/lib/python3.6/site-packages/allennlp/common/params.py:531: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if dictionary[key] == \"None\":\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]\n",
      "  0%|          | 0/538 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Embedding\n",
      "DIRECTORY: test_outputs/imdb/lstm+tanh/Thu_Jun_16_19:37:17_2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/538 [00:04<40:05,  4.48s/it]\u001b[A\n",
      "  0%|          | 2/538 [00:04<28:52,  3.23s/it]\u001b[A\n",
      "  1%|          | 3/538 [00:05<22:44,  2.55s/it]\u001b[A\n",
      "  1%|          | 4/538 [00:09<26:02,  2.93s/it]\u001b[A\n",
      "  1%|          | 5/538 [00:09<19:05,  2.15s/it]\u001b[A\n",
      "  1%|          | 6/538 [00:10<14:59,  1.69s/it]\u001b[A\n",
      "  1%|▏         | 7/538 [00:10<11:39,  1.32s/it]\u001b[A\n",
      "  1%|▏         | 8/538 [00:12<11:56,  1.35s/it]\u001b[A\n",
      "  2%|▏         | 9/538 [00:14<12:37,  1.43s/it]\u001b[A\n",
      "  2%|▏         | 10/538 [00:15<12:10,  1.38s/it]\u001b[A\n",
      "  2%|▏         | 11/538 [00:17<14:34,  1.66s/it]\u001b[A\n",
      "  2%|▏         | 12/538 [00:18<12:30,  1.43s/it]\u001b[A\n",
      "  2%|▏         | 13/538 [00:20<14:26,  1.65s/it]\u001b[A\n",
      "  3%|▎         | 14/538 [00:21<13:04,  1.50s/it]\u001b[A\n",
      "  3%|▎         | 15/538 [00:24<15:03,  1.73s/it]\u001b[A\n",
      "  3%|▎         | 16/538 [00:24<12:37,  1.45s/it]\u001b[A\n",
      "  3%|▎         | 17/538 [00:26<12:18,  1.42s/it]\u001b[A\n",
      "  3%|▎         | 18/538 [00:28<14:02,  1.62s/it]\u001b[A\n",
      "  4%|▎         | 19/538 [00:30<16:30,  1.91s/it]\u001b[A\n",
      "  4%|▎         | 20/538 [00:34<21:06,  2.45s/it]\u001b[A\n",
      "  4%|▍         | 21/538 [00:36<19:19,  2.24s/it]\u001b[A\n",
      "  4%|▍         | 22/538 [00:37<15:16,  1.78s/it]\u001b[A\n",
      "  4%|▍         | 23/538 [00:38<13:12,  1.54s/it]\u001b[A\n",
      "  4%|▍         | 24/538 [00:38<11:31,  1.35s/it]\u001b[A\n",
      "  5%|▍         | 25/538 [00:45<25:45,  3.01s/it]\u001b[A\n",
      "  5%|▍         | 26/538 [00:52<35:11,  4.12s/it]\u001b[A\n",
      "  5%|▌         | 27/538 [00:54<29:32,  3.47s/it]\u001b[A\n",
      "  5%|▌         | 28/538 [00:54<21:56,  2.58s/it]\u001b[A\n",
      "  5%|▌         | 29/538 [01:03<35:45,  4.22s/it]\u001b[A\n",
      "  6%|▌         | 30/538 [01:09<40:56,  4.84s/it]\u001b[A\n",
      "  6%|▌         | 31/538 [01:15<44:03,  5.21s/it]\u001b[A\n",
      "  6%|▌         | 32/538 [01:16<33:27,  3.97s/it]\u001b[A\n",
      "  6%|▌         | 33/538 [01:19<32:12,  3.83s/it]\u001b[A\n",
      "  6%|▋         | 34/538 [01:22<28:44,  3.42s/it]\u001b[A\n",
      "  7%|▋         | 35/538 [01:23<22:48,  2.72s/it]\u001b[A\n",
      "  7%|▋         | 36/538 [01:25<21:08,  2.53s/it]\u001b[A\n",
      "  7%|▋         | 37/538 [01:27<18:50,  2.26s/it]\u001b[A\n",
      "  7%|▋         | 38/538 [01:27<13:37,  1.64s/it]\u001b[A\n",
      "  7%|▋         | 39/538 [01:27<10:29,  1.26s/it]\u001b[A\n",
      "  7%|▋         | 40/538 [01:29<12:07,  1.46s/it]\u001b[A\n",
      "  8%|▊         | 41/538 [01:36<25:09,  3.04s/it]\u001b[A\n",
      "  8%|▊         | 42/538 [01:36<18:44,  2.27s/it]\u001b[A\n",
      "  8%|▊         | 43/538 [01:37<13:31,  1.64s/it]\u001b[A\n",
      "  8%|▊         | 44/538 [01:40<17:48,  2.16s/it]\u001b[A\n",
      "  8%|▊         | 45/538 [01:47<30:30,  3.71s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# # from attention.configurations import generate_config\n",
    "# # from attention.Trainers.TrainerBC import Trainer, Evaluator\n",
    "#\n",
    "# def train_dataset(dataset, args, config='lstm') :\n",
    "#         config = generate_config(dataset, args, config)\n",
    "#         trainer = Trainer(dataset, args, config=config)\n",
    "#         #go ahead and save model\n",
    "#         dirname = trainer.model.save_values(save_model=False)\n",
    "#         print(\"DIRECTORY:\", dirname)\n",
    "#         if args.adversarial :\n",
    "#             trainer.train_adversarial(dataset.train_data, dataset.test_data, args)\n",
    "#         # elif args.ours:\n",
    "#         #     from attention.attack import  PGDAttacker\n",
    "#         #     PGDer = PGDAttacker(\n",
    "#         #         radius=args.pgd_radius, steps=args.pgd_step, step_size=args.pgd_step_size, random_start= \\\n",
    "#         #         True, norm_type=args.pgd_norm_type, ascending=True\n",
    "#         #     )\n",
    "#         #     trainer.PGDer = PGDer\n",
    "#         #     trainer.train_ours(dataset.train_data, dataset.test_data, args)\n",
    "#         else:\n",
    "#             trainer.train_standard(dataset.train_data, dataset.test_data, args, save_on_metric=dataset.save_on_metric)\n",
    "#         print('####################################')\n",
    "#         print(\"TEST RESULTS FROM BEST MODEL\")\n",
    "#         evaluator = Evaluator(dataset, trainer.model.dirname, args)\n",
    "#         _ = evaluator.evaluate(dataset.test_data, save_results=True)\n",
    "#         return trainer, evaluator\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# train_dataset_on_encoders(dataset, args, exp_name)\n",
    "# train_dataset(dataset, args, exp_name)\n",
    "# args, exp_name\n",
    "# exp_name =\n",
    "config = exp_name\n",
    "config = generate_config(dataset, args, config)\n",
    "trainer = Trainer(dataset, args, config=config)\n",
    "#go ahead and save model\n",
    "dirname = trainer.model.save_values(save_model=False)\n",
    "print(\"DIRECTORY:\", dirname)\n",
    "if args.adversarial :\n",
    "    trainer.train_adversarial(dataset.train_data, dataset.test_data, args)\n",
    "# elif args.ours:\n",
    "#     from attention.attack import  PGDAttacker\n",
    "#     PGDer = PGDAttacker(\n",
    "#         radius=args.pgd_radius, steps=args.pgd_step, step_size=args.pgd_step_size, random_start= \\\n",
    "#         True, norm_type=args.pgd_norm_type, ascending=True\n",
    "#     )\n",
    "#     trainer.PGDer = PGDer\n",
    "#     trainer.train_ours(dataset.train_data, dataset.test_data, args)\n",
    "else:\n",
    "    trainer.train_standard(dataset.train_data, dataset.test_data, args, save_on_metric=dataset.save_on_metric)\n",
    "print('####################################')\n",
    "print(\"TEST RESULTS FROM BEST MODEL\")\n",
    "evaluator = Evaluator(dataset, trainer.model.dirname, args)\n",
    "_ = evaluator.evaluate(dataset.test_data, save_results=True)\n",
    "\n",
    "\n",
    "print(\"TOTAL ELAPSED TIME: %f HOURS OR %f MINUTES\" % (((time.time() - start)/60/60), ((time.time() - start)/60)))\n",
    "# _python_exit()\n",
    "# sys.exit()\n",
    "# wandb.log({\n",
    "#     \"finish\":'True'\n",
    "# })\n",
    "# import os\n",
    "# import signal\n",
    "# os.kill(os.getpid(), signal.SIGKILL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "xai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
